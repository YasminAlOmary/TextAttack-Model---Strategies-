{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Uj-OKuEG6m",
        "outputId": "33839e8f-e574-42dd-b99b-afac32232932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textattack\n",
            "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting bert-score>=0.3.5 (from textattack)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from textattack) (0.8.1)\n",
            "Collecting flair (from textattack)\n",
            "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from textattack) (3.17.0)\n",
            "Collecting language-tool-python (from textattack)\n",
            "  Downloading language_tool_python-2.9.0-py3-none-any.whl.metadata (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lemminflect (from textattack)\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting lru-dict (from textattack)\n",
            "  Downloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting datasets>=2.4.0 (from textattack)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from textattack) (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from textattack) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from textattack) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from textattack) (1.13.1)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from textattack) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from textattack) (4.48.3)\n",
            "Collecting terminaltables (from textattack)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from textattack) (4.67.1)\n",
            "Collecting word2number (from textattack)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from textattack)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from textattack) (10.6.0)\n",
            "Collecting pinyin>=0.4.0 (from textattack)\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from textattack) (0.42.1)\n",
            "Collecting OpenHowNet (from textattack)\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.5->textattack) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.5->textattack) (24.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.4.0->textattack)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.4.0->textattack)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.4.0->textattack)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.4.0->textattack) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.4.0->textattack) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->textattack) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->textattack) (2025.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch!=1.8,>=1.7.0->textattack)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->textattack) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->textattack) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->textattack) (0.5.2)\n",
            "Collecting boto3>=1.20.27 (from flair->textattack)\n",
            "  Downloading boto3-1.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair->textattack)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (1.2.18)\n",
            "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (5.2.0)\n",
            "Collecting langdetect>=1.0.9 (from flair->textattack)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (5.3.1)\n",
            "Collecting mpld3>=0.3 (from flair->textattack)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair->textattack)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (1.6.1)\n",
            "Collecting segtok>=1.5.11 (from flair->textattack)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair->textattack) (0.9.0)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python->textattack) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python->textattack) (0.10.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->textattack) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->textattack) (1.4.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree (from OpenHowNet->textattack)\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from OpenHowNet->textattack) (75.1.0)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.38.0,>=1.37.0 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading botocore-1.37.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.18.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair->textattack) (4.13.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect>=1.0.9->flair->textattack) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score>=0.3.5->textattack) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score>=0.3.5->textattack) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair->textattack) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair->textattack) (4.25.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (3.0.2)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.6)\n",
            "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
            "Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.7/445.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading language_tool_python-2.9.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.37.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.0-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: pinyin, word2number, docopt, langdetect, pptree, sqlitedict, wikipedia-api, intervaltree\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630477 sha256=d916f698d85d9aeb8ccb0c5d76841717408ff274a92fd1725ad8d7264969815c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/31/ac8c91eccb570a59fe5f1471ad9f11bece8f4fd4be1ab1be25\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=46f72da55f00455ccda0b7bf69087da44a4158fda81589fb8f480520cef9d187\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=df0c3ae9cb2a3b61f94b9c98a623c34a50c016a7da989a66ed83ff292276ec3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=7a9fb793ba4edc88feb7901d787cce915edab02299398ae3f655899cc59cdf68\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=a868dfcb66d1e691ffdb33a07d72b44d6e55340796f654659ed446df9b55e621\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/8a/eb/d683aa6d09dc68ebfde2f37566ddc8807837c4415b4fd2b04c\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=2ea9a6c073acaf87d091dd66b094d64e6c1635916b7228211ecbe528e8890747\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15384 sha256=c97c51d33d2b89266547d8fa72a8a1ccbd85c43a785caea4b576348efac64b92\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=214b86cbbb5fa95dd431c97c49f8758c3db77af56777939072845cf2ad2fdbd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built pinyin word2number docopt langdetect pptree sqlitedict wikipedia-api intervaltree\n",
            "Installing collected packages: word2number, sqlitedict, sortedcontainers, pptree, pinyin, docopt, xxhash, terminaltables, segtok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, num2words, lru-dict, lemminflect, langdetect, jsonlines, jmespath, intervaltree, ftfy, dill, conllu, anytree, wikipedia-api, OpenHowNet, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, language-tool-python, botocore, bioc, s3transfer, nvidia-cusolver-cu12, mpld3, datasets, boto3, pytorch-revgrad, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed OpenHowNet-2.0 anytree-2.12.1 bert-score-0.3.13 bioc-2.1 boto3-1.37.0 botocore-1.37.0 conllu-4.5.3 datasets-3.3.2 dill-0.3.8 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 language-tool-python-2.9.0 lemminflect-0.2.3 lru-dict-1.3.0 mpld3-0.5.10 multiprocess-0.70.16 num2words-0.5.14 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pinyin-0.4.0 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.11.2 segtok-1.5.11 sortedcontainers-2.4.0 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.10 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.8.1 word2number-1.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install textattack"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepWordBug"
      ],
      "metadata": {
        "id": "nzlr3_eFHQ2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model-from-huggingface bert-base-multilingual-cased --dataset-from-file arabic_preprocessed_data-3.py --recipe deepwordbug --num-examples 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b8d193-b812-467d-a3c9-11d64d67f75f",
        "id": "GI9jX5cgYx0u"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-24 22:42:12.142835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740436932.171483    1722 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740436932.179846    1722 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-24 22:42:12.207705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading model and tokenizer from file: None\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading module from `\u001b[94marabic_preprocessed_data-3.py\u001b[0m`.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mbert-base-multilingual-cased\u001b[0m\n",
            "config.json: 100% 625/625 [00:00<00:00, 3.64MB/s]\n",
            "model.safetensors: 100% 714M/714M [00:04<00:00, 143MB/s]\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 222kB/s]\n",
            "vocab.txt: 100% 996k/996k [00:00<00:00, 4.98MB/s]\n",
            "tokenizer.json: 100% 1.96M/1.96M [00:00<00:00, 7.19MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  unk\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapNeighboringCharacterSwap(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (1): WordSwapRandomCharacterSubstitution(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (2): WordSwapRandomCharacterDeletion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (3): WordSwapRandomCharacterInsertion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): LevenshteinEditDistance(\n",
            "        (max_edit_distance):  30\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): RepeatModification\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  5% 1/20 [00:30<09:30, 30.04s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "الفيلم رائع جدا استمتعت لحظة \u001b[92mالسينما\u001b[0m التجربة \u001b[92mممتعة\u001b[0m\n",
            "\n",
            "الفيلم رائع جدا استمتعت لحظة \u001b[91mالسينمp\u001b[0m التجربة \u001b[91mممcعة\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  10% 2/20 [00:57<08:36, 28.68s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n",
            "\n",
            "الطعام بارد جدا المطعم غير نظيف اكرر الزيارة \u001b[91mمرة\u001b[0m اخرى\n",
            "\n",
            "الطعام بارد جدا المطعم غير نظيف اكرر الزيارة \u001b[92mمرlة\u001b[0m اخرى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  15% 3/20 [01:31<08:37, 30.43s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "احببت المكان جدا الناس ودودون \u001b[92mالخدمة\u001b[0m سريعة الطعام شهي \u001b[92mجدا\u001b[0m\n",
            "\n",
            "احببت المكان جدا الناس ودودون \u001b[91mالدمة\u001b[0m سريعة الطعام شهي \u001b[91mMجدا\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  20% 4/20 [01:54<07:38, 28.63s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n",
            "\n",
            "انصح المتجر يفتقر \u001b[91mالتنوع\u001b[0m المنتجات اسواره مرتفعة جدا\n",
            "\n",
            "انصح المتجر يفتقر \u001b[92mلتنوع\u001b[0m المنتجات اسواره مرتفعة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  25% 5/20 [02:22<07:06, 28.45s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (50%)\u001b[0m\n",
            "\n",
            "التجربة سيئة جدا تاخر \u001b[91mوصول\u001b[0m الطلب عدة ساعات الطعام غير طازج\n",
            "\n",
            "التجربة سيئة جدا تاخر \u001b[92mوصdول\u001b[0m الطلب عدة ساعات الطعام غير طازج\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  30% 6/20 [02:48<06:33, 28.12s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92m1 (50%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "الفيلم مشوق جدا الاداء التمثيلي ممتاز اعجبني شيء العمل \u001b[92mالفني\u001b[0m\n",
            "\n",
            "الفيلم مشوق جدا الاداء التمثيلي ممتاز اعجبني شيء العمل \u001b[91mلافني\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 0 / 0 / 6:  35% 7/20 [03:23<06:17, 29.04s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m0 (50%)\u001b[0m\n",
            "\n",
            "\u001b[92mالفندق\u001b[0m رائع جدا الخدمة ممتازة الغرف صغيرة \u001b[92mجدا\u001b[0m\n",
            "\n",
            "\u001b[91mالفنlق\u001b[0m رائع جدا الخدمة ممتازة الغرف صغيرة \u001b[91mدا\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 0 / 7:  40% 8/20 [03:45<05:38, 28.20s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n",
            "\n",
            "الطعام المكان غير طيب الاطلاق اتمكن \u001b[91mانهاء\u001b[0m الوجبة\n",
            "\n",
            "الطعام المكان غير طيب الاطلاق اتمكن \u001b[92mاiنهاء\u001b[0m الوجبة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 8 / 0 / 0 / 8:  45% 9/20 [04:16<05:13, 28.50s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "الرحلة الجبال رائعة الطقس رائع \u001b[92mالمنظر\u001b[0m طبيعيا \u001b[92mجدا\u001b[0m\n",
            "\n",
            "الرحلة الجبال رائعة الطقس رائع \u001b[91mالمنظyر\u001b[0m طبيعيا \u001b[91mدا\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 0 / 9:  50% 10/20 [04:54<04:54, 29.40s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (50%)\u001b[0m\n",
            "\n",
            "الخدمة بطيئة جدا الطعام \u001b[91mيفتقر\u001b[0m النكهة \u001b[91mاعود\u001b[0m المطعم\n",
            "\n",
            "الخدمة بطيئة جدا الطعام \u001b[92mيتقر\u001b[0m النكهة \u001b[92mاود\u001b[0m المطعم\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 0 / 10:  55% 11/20 [05:33<04:32, 30.32s/it]--------------------------------------------- Result 11 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "سعيد جدا التجربة \u001b[92mالجو\u001b[0m \u001b[92mهادئ\u001b[0m \u001b[92mالمكان\u001b[0m مريح جدا\n",
            "\n",
            "سعيد جدا التجربة \u001b[91mالوج\u001b[0m \u001b[91mهvادئ\u001b[0m \u001b[91mاEمكان\u001b[0m مريح جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 0 / 11:  60% 12/20 [05:35<03:43, 27.94s/it]--------------------------------------------- Result 12 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الهاتف جيدا البطارية تدوم طويلا سعره مرتفعا جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 1 / 12:  65% 13/20 [05:56<03:12, 27.45s/it]--------------------------------------------- Result 13 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "الكتاب ممتازا جميع الجوانب \u001b[92mسواء\u001b[0m الاسلوب المحتوى\n",
            "\n",
            "الكتاب ممتازا جميع الجوانب \u001b[91mسوا\u001b[0m الاسلوب المحتوى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 12 / 0 / 1 / 13:  70% 14/20 [06:42<02:52, 28.72s/it]--------------------------------------------- Result 14 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m0 (50%)\u001b[0m\n",
            "\n",
            "\u001b[92mالجو\u001b[0m \u001b[92mالمدينة\u001b[0m حارا جدا كانت مناطق \u001b[92mباردة\u001b[0m يمكن \u001b[92mالاستمتاع\u001b[0m\n",
            "\n",
            "\u001b[91mالوج\u001b[0m \u001b[91mالميدنة\u001b[0m حارا جدا كانت مناطق \u001b[91mباردq\u001b[0m يمكن \u001b[91mالاستsمتاع\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 13 / 0 / 1 / 14:  75% 15/20 [07:18<02:26, 29.22s/it]--------------------------------------------- Result 15 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n",
            "\n",
            "\u001b[91mالسيارة\u001b[0m ممتازة للاسف السعر مرتفعا بشكل غير معقول \u001b[91mبالنسبة\u001b[0m المميزات تقدمها\n",
            "\n",
            "\u001b[92mGلسيارة\u001b[0m ممتازة للاسف السعر مرتفعا بشكل غير معقول \u001b[92mFالنسبة\u001b[0m المميزات تقدمها\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 14 / 0 / 1 / 15:  80% 16/20 [07:19<01:49, 27.50s/it]--------------------------------------------- Result 16 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطائرة متأخرة وصلت الخدمة متن الطائرة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 14 / 0 / 2 / 16:  85% 17/20 [07:43<01:21, 27.29s/it]--------------------------------------------- Result 17 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m0 (52%)\u001b[0m\n",
            "\n",
            "الحفلة رائعة جدا الموسيقى مميزة الاجواء مليئة \u001b[92mالحيوية\u001b[0m\n",
            "\n",
            "الحفلة رائعة جدا الموسيقى مميزة الاجواء مليئة \u001b[91mالحيويq\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 15 / 0 / 2 / 17:  90% 18/20 [07:45<00:51, 25.87s/it]--------------------------------------------- Result 18 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الفيلم طويلا جدا الحوار بطيئا استمتعت تفاصيله\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 15 / 0 / 3 / 18:  95% 19/20 [08:08<00:25, 25.74s/it]--------------------------------------------- Result 19 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "\u001b[92mالموقع\u001b[0m رائع هادئ يمكن المرء الاسترخاء بشكل تام\n",
            "\n",
            "\u001b[91mالموTع\u001b[0m رائع هادئ يمكن المرء الاسترخاء بشكل تام\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 16 / 0 / 3 / 19: 100% 20/20 [08:10<00:00, 24.54s/it]--------------------------------------------- Result 20 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الغرف الفندق غير نظيفة تماما الخدمة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 16 / 0 / 4 / 20: 100% 20/20 [08:10<00:00, 24.54s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 16     |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 4      |\n",
            "| Original accuracy:            | 80.0%  |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 19.59% |\n",
            "| Average num. words per input: | 8.55   |\n",
            "| Avg num queries:              | 16.75  |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\tTextBugger"
      ],
      "metadata": {
        "id": "F-uKG4fENDGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model-from-huggingface bert-base-multilingual-cased --dataset-from-file arabic_preprocessed_data-3.py --recipe textbugger --num-examples 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302ee6b3-dce1-4594-e638-91a0ddeaa3d0",
        "id": "FD5IpnsNNPbQ"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-24 23:05:55.442305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740438355.488271    7391 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740438355.502533    7391 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-24 23:05:55.557629: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading model and tokenizer from file: None\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading module from `\u001b[94marabic_preprocessed_data-3.py\u001b[0m`.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mbert-base-multilingual-cased\u001b[0m\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34;1mtextattack\u001b[0m: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.\n",
            "100% 481M/481M [00:11<00:00, 42.3MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unzipping file /root/.cache/textattack/tmp47s_3gl1.zip to /root/.cache/textattack/word_embeddings/paragramcf.\n",
            "\u001b[34;1mtextattack\u001b[0m: Successfully saved word_embeddings/paragramcf to cache.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapRandomCharacterInsertion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (1): WordSwapRandomCharacterDeletion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (2): WordSwapNeighboringCharacterSwap(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (3): WordSwapHomoglyphSwap\n",
            "    (4): WordSwapEmbedding(\n",
            "        (max_candidates):  5\n",
            "        (embedding):  WordEmbedding\n",
            "      )\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.8\n",
            "        (window_size):  inf\n",
            "        (skip_text_shorter_than_window):  False\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): RepeatModification\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  5% 1/20 [00:01<00:36,  1.92s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[91m0 (53%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الفيلم رائع جدا استمتعت لحظة السينما التجربة ممتعة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10% 2/20 [00:04<00:40,  2.25s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92m1 (50%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطعام بارد جدا المطعم غير نظيف اكرر الزيارة مرة اخرى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  10% 2/20 [00:04<00:40,  2.25s/it]2025-02-24 23:07:23.114046: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  15% 3/20 [01:02<05:53, 20.81s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m0 (50%)\u001b[0m\n",
            "\n",
            "احببت المكان جدا الناس ودودون \u001b[92mالخدمة\u001b[0m \u001b[92mسريعة\u001b[0m الطعام شهي جدا\n",
            "\n",
            "احببت المكان جدا الناس ودودون \u001b[91mالخمة\u001b[0m \u001b[91mسر\u001b[0m \u001b[91mيعة\u001b[0m الطعام شهي جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  20% 4/20 [01:39<06:39, 24.98s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "انصح المتجر يفتقر التنوع المنتجات اسواره مرتفعة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 2 / 4:  25% 5/20 [01:41<05:04, 20.32s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "التجربة سيئة جدا تاخر وصول الطلب عدة ساعات الطعام غير طازج\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 3 / 5:  30% 6/20 [01:43<04:01, 17.22s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[91m0 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الفيلم مشوق جدا الاداء التمثيلي ممتاز اعجبني شيء العمل الفني\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 4 / 6:  35% 7/20 [02:08<03:58, 18.34s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m0 (50%)\u001b[0m\n",
            "\n",
            "الفندق رائع \u001b[92mجدا\u001b[0m \u001b[92mالخدمة\u001b[0m ممتازة الغرف صغيرة جدا\n",
            "\n",
            "الفندق رائع \u001b[91mجا\u001b[0m \u001b[91mالخد\u001b[0m \u001b[91mمة\u001b[0m ممتازة الغرف صغيرة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 1 / 4 / 7:  40% 8/20 [02:10<03:15, 16.29s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92m1 (50%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطعام المكان غير طيب الاطلاق اتمكن انهاء الوجبة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 1 / 5 / 8:  45% 9/20 [02:12<02:42, 14.76s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الرحلة الجبال رائعة الطقس رائع المنظر طبيعيا جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 1 / 6 / 9:  50% 10/20 [02:37<02:37, 15.76s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (50%)\u001b[0m\n",
            "\n",
            "الخدمة بطيئة جدا الطعام \u001b[91mيفتقر\u001b[0m \u001b[91mالنكهة\u001b[0m اعود المطعم\n",
            "\n",
            "الخدمة بطيئة جدا الطعام \u001b[92mي\u001b[0m \u001b[92mفتقر\u001b[0m \u001b[92mالنهكة\u001b[0m اعود المطعم\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 1 / 6 / 10:  55% 11/20 [03:00<02:27, 16.38s/it]--------------------------------------------- Result 11 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "سعيد \u001b[92mجدا\u001b[0m التجربة الجو \u001b[92mهادئ\u001b[0m المكان مريح جدا\n",
            "\n",
            "سعيد \u001b[91mجا\u001b[0m التجربة الجو \u001b[91mه\u001b[0m \u001b[91mادئ\u001b[0m المكان مريح جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 1 / 6 / 11:  60% 12/20 [03:29<02:19, 17.46s/it]--------------------------------------------- Result 12 ---------------------------------------------\n",
            "\u001b[91m0 (52%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الهاتف جيدا البطارية تدوم طويلا سعره مرتفعا جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 2 / 6 / 12:  65% 13/20 [03:31<01:53, 16.25s/it]--------------------------------------------- Result 13 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الكتاب ممتازا جميع الجوانب سواء الاسلوب المحتوى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 2 / 7 / 13:  70% 14/20 [03:32<01:31, 15.21s/it]--------------------------------------------- Result 14 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الجو المدينة حارا جدا كانت مناطق باردة يمكن الاستمتاع\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 2 / 8 / 14:  75% 15/20 [04:34<01:31, 18.31s/it]--------------------------------------------- Result 15 ---------------------------------------------\n",
            "\u001b[91m0 (52%)\u001b[0m --> \u001b[92m1 (50%)\u001b[0m\n",
            "\n",
            "السيارة ممتازة \u001b[91mللاسف\u001b[0m \u001b[91mالسعر\u001b[0m مرتفعا \u001b[91mبشكل\u001b[0m غير معقول \u001b[91mبالنسبة\u001b[0m المميزات تقدمها\n",
            "\n",
            "السيارة ممتازة \u001b[92mلالسف\u001b[0m \u001b[92mاسلعر\u001b[0m مرتفعا \u001b[92mبكشل\u001b[0m غير معقول \u001b[92mبلانسبة\u001b[0m المميزات تقدمها\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 2 / 8 / 15:  80% 16/20 [04:36<01:09, 17.27s/it]--------------------------------------------- Result 16 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطائرة متأخرة وصلت الخدمة متن الطائرة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 2 / 9 / 16:  85% 17/20 [04:59<00:52, 17.61s/it]--------------------------------------------- Result 17 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "الحفلة رائعة جدا \u001b[92mالموسيقى\u001b[0m مميزة الاجواء مليئة الحيوية\n",
            "\n",
            "الحفلة رائعة جدا \u001b[91mالمو\u001b[0m \u001b[91mسيقى\u001b[0m مميزة الاجواء مليئة الحيوية\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 2 / 9 / 17:  90% 18/20 [05:18<00:35, 17.70s/it]--------------------------------------------- Result 18 ---------------------------------------------\n",
            "\u001b[91m0 (52%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الفيلم طويلا جدا الحوار بطيئا استمتعت تفاصيله\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 3 / 9 / 18:  95% 19/20 [05:20<00:16, 16.85s/it]--------------------------------------------- Result 19 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الموقع رائع هادئ يمكن المرء الاسترخاء بشكل تام\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 3 / 10 / 19: 100% 20/20 [05:22<00:00, 16.11s/it]--------------------------------------------- Result 20 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الغرف الفندق غير نظيفة تماما الخدمة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 3 / 11 / 20: 100% 20/20 [05:22<00:00, 16.11s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 6      |\n",
            "| Number of failed attacks:     | 3      |\n",
            "| Number of skipped attacks:    | 11     |\n",
            "| Original accuracy:            | 45.0%  |\n",
            "| Accuracy under attack:        | 15.0%  |\n",
            "| Attack success rate:          | 66.67% |\n",
            "| Average perturbed word %:     | 56.06% |\n",
            "| Average num. words per input: | 8.55   |\n",
            "| Avg num queries:              | 17.0   |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\tTextFooler"
      ],
      "metadata": {
        "id": "k7fLlKmAPGrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model-from-huggingface bert-base-multilingual-cased --dataset-from-file arabic_preprocessed_data-3.py --recipe textfooler --num-examples 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6b3b2f-55c2-4252-d61f-6a35df2fc050",
        "id": "NgaY4j4iPH5P"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-24 23:14:30.933788: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740438870.973212    9463 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740438870.984092    9463 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-24 23:14:31.045460: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading model and tokenizer from file: None\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading module from `\u001b[94marabic_preprocessed_data-3.py\u001b[0m`.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mbert-base-multilingual-cased\u001b[0m\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  5% 1/20 [00:17<05:24, 17.08s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الفيلم رائع جدا استمتعت لحظة السينما التجربة ممتعة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  10% 2/20 [00:18<02:49,  9.40s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطعام بارد جدا المطعم غير نظيف اكرر الزيارة مرة اخرى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:  15% 3/20 [00:38<03:35, 12.69s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "احببت المكان جدا الناس ودودون الخدمة سريعة الطعام شهي جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 2 / 1 / 3:  20% 4/20 [00:40<02:42, 10.18s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "انصح المتجر يفتقر التنوع المنتجات اسواره مرتفعة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 2 / 2 / 4:  25% 5/20 [00:42<02:07,  8.47s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "التجربة سيئة جدا تاخر وصول الطلب عدة ساعات الطعام غير طازج\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 2 / 3 / 5:  30% 6/20 [01:06<02:36, 11.17s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الفيلم مشوق جدا الاداء التمثيلي ممتاز اعجبني شيء العمل الفني\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 3 / 3 / 6:  35% 7/20 [01:26<02:39, 12.30s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الفندق رائع جدا الخدمة ممتازة الغرف صغيرة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 4 / 3 / 7:  40% 8/20 [01:27<02:11, 10.97s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطعام المكان غير طيب الاطلاق اتمكن انهاء الوجبة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 4 / 4 / 8:  45% 9/20 [01:43<02:06, 11.54s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الرحلة الجبال رائعة الطقس رائع المنظر طبيعيا جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 5 / 4 / 9:  50% 10/20 [01:45<01:45, 10.55s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الخدمة بطيئة جدا الطعام يفتقر النكهة اعود المطعم\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 5 / 5 / 10:  55% 11/20 [01:47<01:27,  9.77s/it]--------------------------------------------- Result 11 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "سعيد جدا التجربة الجو هادئ المكان مريح جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 5 / 6 / 11:  60% 12/20 [01:50<01:13,  9.17s/it]--------------------------------------------- Result 12 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الهاتف جيدا البطارية تدوم طويلا سعره مرتفعا جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 5 / 7 / 12:  65% 13/20 [02:04<01:06,  9.57s/it]--------------------------------------------- Result 13 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الكتاب ممتازا جميع الجوانب سواء الاسلوب المحتوى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 6 / 7 / 13:  70% 14/20 [02:22<01:01, 10.17s/it]--------------------------------------------- Result 14 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الجو المدينة حارا جدا كانت مناطق باردة يمكن الاستمتاع\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 7 / 7 / 14:  75% 15/20 [02:24<00:48,  9.60s/it]--------------------------------------------- Result 15 ---------------------------------------------\n",
            "\u001b[92m1 (53%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "السيارة ممتازة للاسف السعر مرتفعا بشكل غير معقول بالنسبة المميزات تقدمها\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 7 / 8 / 15:  80% 16/20 [02:26<00:36,  9.13s/it]--------------------------------------------- Result 16 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطائرة متأخرة وصلت الخدمة متن الطائرة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 7 / 9 / 16:  85% 17/20 [02:42<00:28,  9.59s/it]--------------------------------------------- Result 17 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الحفلة رائعة جدا الموسيقى مميزة الاجواء مليئة الحيوية\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 8 / 9 / 17:  90% 18/20 [02:44<00:18,  9.15s/it]--------------------------------------------- Result 18 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الفيلم طويلا جدا الحوار بطيئا استمتعت تفاصيله\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 8 / 10 / 18:  95% 19/20 [03:00<00:09,  9.52s/it]--------------------------------------------- Result 19 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "الموقع رائع هادئ يمكن المرء الاسترخاء بشكل تام\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 9 / 10 / 19: 100% 20/20 [03:02<00:00,  9.12s/it]--------------------------------------------- Result 20 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الغرف الفندق غير نظيفة تماما الخدمة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 9 / 11 / 20: 100% 20/20 [03:02<00:00,  9.12s/it]\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/textattack/metrics/attack_metrics/words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
            "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "+-------------------------------+-------+\n",
            "| Attack Results                |       |\n",
            "+-------------------------------+-------+\n",
            "| Number of successful attacks: | 0     |\n",
            "| Number of failed attacks:     | 9     |\n",
            "| Number of skipped attacks:    | 11    |\n",
            "| Original accuracy:            | 45.0% |\n",
            "| Accuracy under attack:        | 45.0% |\n",
            "| Attack success rate:          | 0.0%  |\n",
            "| Average perturbed word %:     | nan%  |\n",
            "| Average num. words per input: | 8.55  |\n",
            "| Avg num queries:              | 9.44  |\n",
            "+-------------------------------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\tHotFlip"
      ],
      "metadata": {
        "id": "0FDiCc7CQ5ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model-from-huggingface bert-base-multilingual-cased --dataset-from-file arabic_preprocessed_data-3.py --recipe hotflip --num-examples 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea13766-86cb-47e6-d9b7-5bd87905962f",
        "id": "Q-n1PWc9RAjn"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-24 23:22:10.702458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740439330.733118   11302 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740439330.742470   11302 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-24 23:22:10.773246: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading model and tokenizer from file: None\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading module from `\u001b[94marabic_preprocessed_data-3.py\u001b[0m`.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mbert-base-multilingual-cased\u001b[0m\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/textattack\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/commands/textattack_cli.py\", line 49, in main\n",
            "    func.run(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/commands/attack_command.py\", line 32, in run\n",
            "    attack = CommandLineAttackArgs._create_attack_from_args(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attack_args.py\", line 703, in _create_attack_from_args\n",
            "    recipe = eval(\n",
            "             ^^^^^\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attack_recipes/hotflip_ebrahimi_2017.py\", line 41, in build\n",
            "    transformation = WordSwapGradientBased(model_wrapper, top_n=1)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/transformations/word_swaps/word_swap_gradient_based.py\", line 44, in __init__\n",
            "    validate_model_gradient_word_swap_compatibility(self.model)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/shared/validators.py\", line 98, in validate_model_gradient_word_swap_compatibility\n",
            "    raise ValueError(f\"Cannot perform GradientBasedWordSwap on model {model}.\")\n",
            "ValueError: Cannot perform GradientBasedWordSwap on model BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ").\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BAE"
      ],
      "metadata": {
        "id": "qmIhOg6rRWfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model-from-huggingface bert-base-multilingual-cased --dataset-from-file arabic_preprocessed_data-3.py --recipe bae --num-examples 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a3ecb9-7d11-4162-a258-a7b799296f7b",
        "id": "qf_F35q7RhRf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-24 23:24:14.980609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740439455.018227   11809 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740439455.026836   11809 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-24 23:24:15.060958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading model and tokenizer from file: None\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading module from `\u001b[94marabic_preprocessed_data-3.py\u001b[0m`.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mbert-base-multilingual-cased\u001b[0m\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.09MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:05<00:00, 75.3MB/s]\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 128kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 3.11MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 3.35MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapMaskedLM(\n",
            "    (method):  bae\n",
            "    (masked_lm_name):  BertForMaskedLM\n",
            "    (max_length):  512\n",
            "    (max_candidates):  50\n",
            "    (min_confidence):  0.0\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): UniversalSentenceEncoder(\n",
            "        (metric):  cosine\n",
            "        (threshold):  0.936338023\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): RepeatModification\n",
            "    (3): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  5% 1/20 [00:01<00:36,  1.93s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[91m0 (55%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الفيلم رائع جدا استمتعت لحظة السينما التجربة ممتعة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   5% 1/20 [00:01<00:36,  1.93s/it]Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/textattack\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/commands/textattack_cli.py\", line 49, in main\n",
            "    func.run(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/commands/attack_command.py\", line 36, in run\n",
            "    attacker.attack_dataset()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attacker.py\", line 441, in attack_dataset\n",
            "    self._attack()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attacker.py\", line 170, in _attack\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attacker.py\", line 168, in _attack\n",
            "    result = self.attack.attack(example, ground_truth_output)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attack.py\", line 450, in attack\n",
            "    result = self._attack(goal_function_result)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attack.py\", line 398, in _attack\n",
            "    final_result = self.search_method(initial_result)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/search_methods/search_method.py\", line 35, in __call__\n",
            "    result = self.perform_search(initial_result)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/search_methods/greedy_word_swap_wir.py\", line 141, in perform_search\n",
            "    transformed_text_candidates = self.get_transformations(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attack.py\", line 315, in get_transformations\n",
            "    return self.filter_transformations(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attack.py\", line 380, in filter_transformations\n",
            "    filtered_texts += self._filter_transformations_uncached(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/attack.py\", line 340, in _filter_transformations_uncached\n",
            "    filtered_texts = C.call_many(filtered_texts, original_text)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/constraints/constraint.py\", line 50, in call_many\n",
            "    filtered_texts = self._check_constraint_many(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/constraints/constraint.py\", line 63, in _check_constraint_many\n",
            "    return [\n",
            "           ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/constraints/constraint.py\", line 66, in <listcomp>\n",
            "    if self._check_constraint(transformed_text, reference_text)\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/constraints/grammaticality/part_of_speech.py\", line 132, in _check_constraint\n",
            "    ref_pos = self._get_pos(before_ctx, reference_word, after_ctx)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/textattack/constraints/grammaticality/part_of_speech.py\", line 90, in _get_pos\n",
            "    *nltk.pos_tag(\n",
            "     ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 168, in pos_tag\n",
            "    tagger = _get_tagger(lang)\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 110, in _get_tagger\n",
            "    tagger = PerceptronTagger()\n",
            "             ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 183, in __init__\n",
            "    self.load_from_json(lang)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 273, in load_from_json\n",
            "    loc = find(f\"taggers/averaged_perceptron_tagger_{lang}/\")\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/data.py\", line 579, in find\n",
            "    raise LookupError(resource_not_found)\n",
            "LookupError: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   5% 1/20 [00:23<07:35, 23.96s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\tBertAttack"
      ],
      "metadata": {
        "id": "wKZ4iCkDR5e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model-from-huggingface bert-base-multilingual-cased --dataset-from-file arabic_preprocessed_data-3.py --recipe bertattack --num-examples 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a68d990-dc92-4f31-87af-6bfec97c198c",
        "id": "5r-aZJv-R_em"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-24 23:26:43.553807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740439603.603674   12409 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740439603.622638   12409 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-24 23:26:43.678472: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: [python -m] textattack <command> [<args>] attack [-h]\n",
            "                                                        [--model MODEL | --model-from-file MODEL_FROM_FILE | --model-from-huggingface MODEL_FROM_HUGGINGFACE]\n",
            "                                                        [--dataset-by-model DATASET_BY_MODEL | --dataset-from-huggingface DATASET_FROM_HUGGINGFACE | --dataset-from-file DATASET_FROM_FILE]\n",
            "                                                        [--dataset-split DATASET_SPLIT]\n",
            "                                                        [--filter-by-labels FILTER_BY_LABELS [FILTER_BY_LABELS ...]]\n",
            "                                                        [--transformation TRANSFORMATION]\n",
            "                                                        [--constraints [CONSTRAINTS ...]]\n",
            "                                                        [--goal-function GOAL_FUNCTION]\n",
            "                                                        [--search-method SEARCH_METHOD | --attack-recipe {alzantot,bae,bert-attack,faster-alzantot,deepwordbug,hotflip,input-reduction,kuleshov,morpheus,seq2sick,textbugger,textfooler,pwws,iga,pruthi,pso,checklist,clare,a2t} | --attack-from-file ATTACK_FROM_FILE]\n",
            "                                                        [--interactive]\n",
            "                                                        [--model-batch-size MODEL_BATCH_SIZE]\n",
            "                                                        [--model-cache-size MODEL_CACHE_SIZE]\n",
            "                                                        [--constraint-cache-size CONSTRAINT_CACHE_SIZE]\n",
            "                                                        [--num-examples NUM_EXAMPLES | --num-successful-examples NUM_SUCCESSFUL_EXAMPLES]\n",
            "                                                        [--num-examples-offset NUM_EXAMPLES_OFFSET]\n",
            "                                                        [--query-budget QUERY_BUDGET] [--shuffle]\n",
            "                                                        [--attack-n]\n",
            "                                                        [--checkpoint-dir CHECKPOINT_DIR]\n",
            "                                                        [--checkpoint-interval CHECKPOINT_INTERVAL]\n",
            "                                                        [--random-seed RANDOM_SEED] [--parallel]\n",
            "                                                        [--num-workers-per-device NUM_WORKERS_PER_DEVICE]\n",
            "                                                        [--log-to-txt [LOG_TO_TXT]]\n",
            "                                                        [--log-to-csv [LOG_TO_CSV]]\n",
            "                                                        [--log-summary-to-json [LOG_SUMMARY_TO_JSON]]\n",
            "                                                        [--csv-coloring-style CSV_COLORING_STYLE]\n",
            "                                                        [--log-to-visdom [LOG_TO_VISDOM]]\n",
            "                                                        [--log-to-wandb [LOG_TO_WANDB]]\n",
            "                                                        [--disable-stdout] [--silent]\n",
            "                                                        [--enable-advance-metrics]\n",
            "[python -m] textattack <command> [<args>] attack: error: argument --attack-recipe/--recipe/-r: invalid choice: 'bertattack' (choose from 'alzantot', 'bae', 'bert-attack', 'faster-alzantot', 'deepwordbug', 'hotflip', 'input-reduction', 'kuleshov', 'morpheus', 'seq2sick', 'textbugger', 'textfooler', 'pwws', 'iga', 'pruthi', 'pso', 'checklist', 'clare', 'a2t')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\tCLARE"
      ],
      "metadata": {
        "id": "eeG1RdYQSXxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model-from-huggingface bert-base-multilingual-cased --dataset-from-file arabic_preprocessed_data-3.py --recipe clare --num-examples 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f9ebdc-3c4d-430a-f363-892eaf02ee47",
        "id": "vdQ3hM5NSdHL"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34;1mtextattack\u001b[0m: Updating TextAttack package dependencies.\n",
            "\u001b[34;1mtextattack\u001b[0m: Downloading NLTK required packages.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "2025-02-25 02:35:54.514448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740450954.910108    1264 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740450954.997874    1264 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-25 02:35:55.679571: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading model and tokenizer from file: None\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading module from `\u001b[94marabic_preprocessed_data-3.py\u001b[0m`.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mbert-base-multilingual-cased\u001b[0m\n",
            "config.json: 100% 625/625 [00:00<00:00, 3.43MB/s]\n",
            "model.safetensors: 100% 714M/714M [00:06<00:00, 118MB/s]\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 300kB/s]\n",
            "vocab.txt: 100% 996k/996k [00:00<00:00, 13.9MB/s]\n",
            "tokenizer.json: 100% 1.96M/1.96M [00:00<00:00, 13.4MB/s]\n",
            "config.json: 100% 480/480 [00:00<00:00, 3.03MB/s]\n",
            "model.safetensors: 100% 331M/331M [00:01<00:00, 198MB/s]\n",
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 127kB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 27.9MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 21.2MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 12.3MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedySearch\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapMaskedLM(\n",
            "        (method):  bae\n",
            "        (masked_lm_name):  RobertaForCausalLM\n",
            "        (max_length):  512\n",
            "        (max_candidates):  50\n",
            "        (min_confidence):  0.0005\n",
            "      )\n",
            "    (1): WordInsertionMaskedLM(\n",
            "        (masked_lm_name):  RobertaForCausalLM\n",
            "        (max_length):  512\n",
            "        (max_candidates):  50\n",
            "        (min_confidence):  0.0\n",
            "      )\n",
            "    (2): WordMergeMaskedLM(\n",
            "        (masked_lm_name):  RobertaForCausalLM\n",
            "        (max_length):  512\n",
            "        (max_candidates):  50\n",
            "        (min_confidence):  0.005\n",
            "      )\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): UniversalSentenceEncoder(\n",
            "        (metric):  cosine\n",
            "        (threshold):  0.7\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): RepeatModification\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  5% 1/20 [00:02<00:39,  2.06s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الفيلم رائع جدا استمتعت لحظة السينما التجربة ممتعة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10% 2/20 [00:03<00:34,  1.92s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطعام بارد جدا المطعم غير نظيف اكرر الزيارة مرة اخرى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  10% 2/20 [00:03<00:34,  1.92s/it]\n",
            "pytorch_model.bin:   0% 0.00/72.9M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model.bin:  14% 10.5M/72.9M [00:00<00:01, 40.7MB/s]\u001b[A\n",
            "pytorch_model.bin:  58% 41.9M/72.9M [00:00<00:00, 119MB/s] \u001b[A\n",
            "pytorch_model.bin: 100% 72.9M/72.9M [00:00<00:00, 131MB/s]\n",
            "2025-02-25 02:37:04,246 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, VERB, PUNCT, ADP, DET, PROPN, PRON, ADJ, ADV, CCONJ, PART, NUM, AUX, INTJ, SYM, X, <START>, <STOP>\n",
            "2025-02-25 02:37:18.310515: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2025-02-25 02:37:19.183612: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-02-25 02:37:19.224928: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-02-25 02:37:19.267578: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-02-25 02:37:19.310443: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2025-02-25 02:37:19.353592: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  15% 3/20 [01:57<11:08, 39.33s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92m1 (50%)\u001b[0m --> \u001b[91m0 (52%)\u001b[0m\n",
            "\n",
            "احببت المكان جدا الناس ودودون الخدمة سريعة الطعام شهي جدا\n",
            "\n",
            "احببت المكان جدا الناس ودودون الخدمة سريعة </\u001b[91ms\u001b[0m> الطعام شهي جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  20% 4/20 [03:48<15:12, 57.02s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[91m0 (53%)\u001b[0m --> \u001b[92m1 (52%)\u001b[0m\n",
            "\n",
            "انصح المتجر يفتقر التنوع المنتجات اسواره مرتفعة \u001b[91mجدا\u001b[0m\n",
            "\n",
            "انصح المتجر يفتقر التنوع المنتجات \u001b[92mand\u001b[0m اسواره مرتفعة \u001b[92mArabic\u001b[0m\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 2 / 4:  25% 5/20 [03:50<11:30, 46.02s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "التجربة سيئة جدا تاخر وصول الطلب عدة ساعات الطعام غير طازج\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 3 / 5:  30% 6/20 [03:52<09:03, 38.80s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الفيلم مشوق جدا الاداء التمثيلي ممتاز اعجبني شيء العمل الفني\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 4 / 6:  35% 7/20 [05:01<09:20, 43.13s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92m1 (50%)\u001b[0m --> \u001b[91m0 (52%)\u001b[0m\n",
            "\n",
            "الفندق رائع جدا الخدمة ممتازة الغرف صغيرة \u001b[92mجدا\u001b[0m\n",
            "\n",
            "الفندق رائع جدا الخدمة ممتازة الغرف صغيرة </\u001b[91ms\u001b[0m>\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 4 / 7:  40% 8/20 [05:48<08:42, 43.56s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n",
            "\n",
            "الطعام المكان غير طيب الاطلاق اتمكن انهاء الوجبة\n",
            "\n",
            "الطعام المكان غير طيب الاطلاق اتمكن انهاء \u001b[92mi\u001b[0m الوجبة\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 4 / 8:  45% 9/20 [05:51<07:09, 39.03s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الرحلة الجبال رائعة الطقس رائع المنظر طبيعيا جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 5 / 9:  50% 10/20 [06:46<06:46, 40.62s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n",
            "\n",
            "الخدمة بطيئة جدا الطعام يفتقر النكهة اعود المطعم\n",
            "\n",
            "الخدمة بطيئة جدا الطعام يفتقر \u001b[92mah\u001b[0m النكهة اعود المطعم\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 5 / 10:  55% 11/20 [08:08<06:39, 44.44s/it]--------------------------------------------- Result 11 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[91m0 (52%)\u001b[0m\n",
            "\n",
            "سعيد جدا التجربة الجو هادئ المكان مريح جدا\n",
            "\n",
            "سعيد جدا </\u001b[91ms\u001b[0m> التجربة الجو هادئ المكان مريح جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 0 / 5 / 11:  60% 12/20 [08:57<05:58, 44.80s/it]--------------------------------------------- Result 12 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[92m1 (50%)\u001b[0m\n",
            "\n",
            "الهاتف جيدا البطارية تدوم طويلا سعره مرتفعا جدا\n",
            "\n",
            "الهاتف جيدا البطارية تدوم طويلا </\u001b[92ms\u001b[0m> سعره مرتفعا جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 5 / 12:  65% 13/20 [08:59<04:50, 41.49s/it]--------------------------------------------- Result 13 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الكتاب ممتازا جميع الجوانب سواء الاسلوب المحتوى\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 6 / 13:  70% 14/20 [09:54<04:14, 42.44s/it]--------------------------------------------- Result 14 ---------------------------------------------\n",
            "\u001b[92m1 (50%)\u001b[0m --> \u001b[91m0 (51%)\u001b[0m\n",
            "\n",
            "الجو المدينة حارا جدا كانت مناطق باردة يمكن الاستمتاع\n",
            "\n",
            "الجو المدينة حارا \u001b[91me\u001b[0m جدا كانت مناطق باردة يمكن الاستمتاع\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 8 / 0 / 6 / 14:  75% 15/20 [12:07<04:02, 48.48s/it]--------------------------------------------- Result 15 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n",
            "\n",
            "السيارة \u001b[91mممتازة\u001b[0m للاسف السعر مرتفعا بشكل غير معقول بالنسبة المميزات تقدمها\n",
            "\n",
            "السيارة </\u001b[92ms\u001b[0m> للاسف السعر مرتفعا بشكل غير معقول بالنسبة </\u001b[92ms\u001b[0m> المميزات تقدمها\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 6 / 15:  80% 16/20 [12:08<03:02, 45.56s/it]--------------------------------------------- Result 16 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الطائرة متأخرة وصلت الخدمة متن الطائرة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 7 / 16:  85% 17/20 [13:30<02:22, 47.65s/it]--------------------------------------------- Result 17 ---------------------------------------------\n",
            "\u001b[92m1 (51%)\u001b[0m --> \u001b[91m0 (52%)\u001b[0m\n",
            "\n",
            "الحفلة رائعة جدا الموسيقى مميزة الاجواء مليئة \u001b[92mالحيوية\u001b[0m\n",
            "\n",
            "الحفلة رائعة جدا الموسيقى مميزة الاجواء مليئة </\u001b[91ms\u001b[0m>\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 7 / 17:  90% 18/20 [14:15<01:35, 47.52s/it]--------------------------------------------- Result 18 ---------------------------------------------\n",
            "\u001b[91m0 (50%)\u001b[0m --> \u001b[92m1 (50%)\u001b[0m\n",
            "\n",
            "الفيلم طويلا جدا الحوار بطيئا استمتعت تفاصيله\n",
            "\n",
            "الفيلم طويلا جدا الحوار بطيئا استمتعت </\u001b[92ms\u001b[0m> تفاصيله\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 7 / 18:  95% 19/20 [14:17<00:45, 45.15s/it]--------------------------------------------- Result 19 ---------------------------------------------\n",
            "\u001b[91m0 (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الموقع رائع هادئ يمكن المرء الاسترخاء بشكل تام\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 8 / 19: 100% 20/20 [14:19<00:00, 42.98s/it]--------------------------------------------- Result 20 ---------------------------------------------\n",
            "\u001b[92m1 (52%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
            "\n",
            "الغرف الفندق غير نظيفة تماما الخدمة سيئة جدا\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 11 / 0 / 9 / 20: 100% 20/20 [14:19<00:00, 42.98s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 11     |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 9      |\n",
            "| Original accuracy:            | 55.0%  |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 33.02% |\n",
            "| Average num. words per input: | 8.55   |\n",
            "| Avg num queries:              | 17.45  |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    }
  ]
}